{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees and tree based ensemble models like random forest and gradient boosted trees are commonly used.  Here, a simple decision tree is coded-up to demonstrate key principles like splitting on features and recursively building branches.  When building trees we want to branch on what gives us the most information at each step which means creating the most homogeneous branches possible.  This is quantified by the entropy difference between the parent node and the children, meaning the difference in quantitative uncertainty, \n",
    "\n",
    "$$E = -\\Sigma p(x)log(p(x))$$\n",
    "\n",
    "where p is the probability of a given class which we can measure as the fraction.\n",
    "\n",
    "Decision trees are good because they are transparent (you can visually display them), but they are very prone to overfitting.  Because of this, they are often used in ensembles, like random forests, but they can become tough to interpret as in random forests each tree is given a certain bit of the data and feature set and used to \"vote\" on the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(class_probabilities):\n",
    "    '''given a list of class probabilities, compute the entropy'''\n",
    "    H = sum(-p*math.log(p, 2) for p in class_probabilities if p) # ignore zeros\n",
    "    return H\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count/total_count for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probs = class_probabilities(labels)\n",
    "    return entropy(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy of a partition is the weighted sum of the proportions of the subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy(subsets):\n",
    "    '''find the entropy from this partition of data into subsets wehre \n",
    "    subsets is a list of lists of labeled data'''\n",
    "    total_count = sum(len(subset) for subset in subsets) # sum over lists\n",
    "    return sum(data_entropy(subset)*len(subset)/total_count #weighted sum\n",
    "              for subset in subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    ({'level':'Senior','lang':'Java','tweets':'no','phd':'no'},   False),\n",
    "    ({'level':'Senior','lang':'Java','tweets':'no','phd':'yes'},  False),\n",
    "    ({'level':'Mid','lang':'Python','tweets':'no','phd':'no'},     True),\n",
    "    ({'level':'Junior','lang':'Python','tweets':'no','phd':'no'},  True),\n",
    "    ({'level':'Junior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "    ({'level':'Junior','lang':'R','tweets':'yes','phd':'yes'},    False),\n",
    "    ({'level':'Mid','lang':'R','tweets':'yes','phd':'yes'},        True),\n",
    "    ({'level':'Senior','lang':'Python','tweets':'no','phd':'no'}, False),\n",
    "    ({'level':'Senior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "    ({'level':'Junior','lang':'Python','tweets':'yes','phd':'no'}, True),\n",
    "    ({'level':'Senior','lang':'Python','tweets':'yes','phd':'yes'},True),\n",
    "    ({'level':'Mid','lang':'Python','tweets':'no','phd':'yes'},    True),\n",
    "    ({'level':'Mid','lang':'Java','tweets':'yes','phd':'no'},      True),\n",
    "    ({'level':'Junior','lang':'Python','tweets':'no','phd':'yes'},False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_by(inputs, attribute):\n",
    "    '''each input is a pair of (attribute_dict, label) \n",
    "    and returns a dict of attribute_value -> inputs'''\n",
    "    \n",
    "    groups = defaultdict(list)\n",
    "    for input in inputs:\n",
    "        key = input[0][attribute]   # get value of specified attribute\n",
    "        groups[key].append(input)   # add input to correct list\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy_by(inputs, attribute):\n",
    "    '''computes the entropy corresponding to given partition'''\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to find the minimum entropy partition for the whole dataset as we want to split on lowest entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0.6935361388961919\n",
      "lang 0.8601317128547441\n",
      "tweets 0.7884504573082896\n",
      "phd 0.8921589282623617\n"
     ]
    }
   ],
   "source": [
    "for key in ['level', 'lang', 'tweets', 'phd']:\n",
    "    print(key, partition_entropy_by(inputs, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, input):\n",
    "    '''classify the input using the decision tree'''\n",
    "    \n",
    "    # if this is a leaf node, return value\n",
    "    if tree in [True, False]:\n",
    "        return tree\n",
    "    \n",
    "    attribute, subtree_dict = tree # unpack dict\n",
    "    subtree_key = input.get(attribute)\n",
    "    \n",
    "    if subtree_key not in subtree_dict:\n",
    "        subtree_key = None\n",
    "        \n",
    "    subtree = subtree_dict[subtree_key]\n",
    "    \n",
    "    # recursively call until we get to the end of the tree\n",
    "    return classify(subtree, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_id3(inputs, split_candidates=None):\n",
    "    \n",
    "    # on first pass all attributes are available to split\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "    \n",
    "    # count Trues and Falses in the inputs\n",
    "    \n",
    "    num_inputs = len(inputs)\n",
    "    num_trues = len([label for item, label in inputs if label])\n",
    "    num_falses = num_inputs - num_trues\n",
    "    \n",
    "    if num_trues == 0: return False    # make \"False\" leaf\n",
    "    if num_falses == 0: return True    # make \"True\" leaf\n",
    "    \n",
    "    if not split_candidates:\n",
    "        return num_trues >= num_falses # if no candidates, return majority leaf\n",
    "    \n",
    "    best_attribute = min(split_candidates, key=partial(partition_entropy_by, inputs))\n",
    "    \n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates if a != best_attribute]\n",
    "    \n",
    "    # recursively build subtrees\n",
    "    subtrees = {attribute_value : build_tree_id3(subset, new_candidates)\n",
    "               for attribute_value, subset in partitions.items()}\n",
    "    \n",
    "    subtrees[None] = num_trues > num_falses   # default case\n",
    "    \n",
    "    return (best_attribute, subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree_id3(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('level', {'Senior': ('tweets', {'no': False, 'yes': True, None: False}), 'Mid': True, 'Junior': ('phd', {'no': True, 'yes': False, None: True}), None: True})\n"
     ]
    }
   ],
   "source": [
    "print (tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
